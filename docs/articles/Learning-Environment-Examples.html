<!DOCTYPE html>
<!--[if IE]><![endif]-->
<html>
  
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>Example Learning Environments </title>
    <meta name="viewport" content="width=device-width">
    <meta name="title" content="Example Learning Environments ">
    <meta name="generator" content="docfx 2.34.0.0">
    
    <link rel="shortcut icon" href="../favicon.ico">
    <link rel="stylesheet" href="../styles/docfx.vendor.css">
    <link rel="stylesheet" href="../styles/docfx.css">
    <link rel="stylesheet" href="../styles/main.css">
    <meta property="docfx:navrel" content="../toc">
    <meta property="docfx:tocrel" content="toc">
    
    
    
  </head>
  <body data-spy="scroll" data-target="#affix">
    <div id="wrapper">
      <header>
        
        <nav id="autocollapse" class="navbar navbar-inverse ng-scope" role="navigation">
          <div class="container">
            <div class="navbar-header">
              <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
              
              <a class="navbar-brand" href="../index.html">
                <img id="logo" src="../images/logo.png" alt="">
              </a>
            </div>
            <div class="collapse navbar-collapse" id="navbar">
              <form class="navbar-form navbar-right" role="search" id="search">
                <div class="form-group">
                  <input type="text" class="form-control" id="search-query" placeholder="Search" autocomplete="off">
                </div>
              </form>
                <ul class="nav level1 navbar-nav">
                  <li class="active">
                    <a href="../articles/ML-Agents-Overview.html" title="Manual" class="active">Manual</a>
                  </li>
                  <li class="">
                    <a href="../zh-CN/ML-Agents-Overview.html" title="Chinese Manual" class="">Chinese Manual</a>
                  </li>
                  <li class="">
                    <a href="../csharp-api/Unity.MLAgents.html" title="C# Script Reference" class="">C# Script Reference</a>
                  </li>
                  <li class="">
                    <a href="../python-api/Python-API.html" title="Python Script Reference" class="">Python Script Reference</a>
                  </li>
                </ul>
            </div>
          </div>
        </nav>
        
        <div class="subnav navbar navbar-default">
          <div class="container hide-when-search" id="breadcrumb">
            <ul class="breadcrumb">
              <li></li>
            </ul>
          </div>
        </div>
      </header>
      <div role="main" class="container body-content hide-when-search">
        <div class="sidenav hide-when-search">
          <a class="btn toc-toggle collapse" data-toggle="collapse" href="#sidetoggle" aria-expanded="false" aria-controls="sidetoggle">Show / Hide Table of Contents</a>
          <div class="sidetoggle collapse" id="sidetoggle">
            <div>
              <div class="sidefilter">
                <form class="toc-filter">
                  <span class="glyphicon glyphicon-filter filter-icon"></span>
                  <input type="text" id="toc_filter_input" placeholder="Enter here to filter..." onkeypress="if(event.keyCode==13) {return false;}">
                </form>
              </div>
              <div class="sidetoc">
                <div class="toc" id="toc">
                  
                  <ul class="nav level1">
                    <li class="">
                      <span class="expand-stub"></span>
                      <a class="">Getting Started</a>
                        
                        <ul class="nav level2">
                          <li class="">
                            <span class="expand-stub"></span>
                            <a href="ML-Agents-Overview.html" title="ML-Agents Overview" class="">ML-Agents Overview</a>
                              
                              <ul class="nav level3">
                                <li class="">
                                  <a href="Background-Unity.html" title="Background Unity" class="">Background Unity</a>
                                </li>
                                <li class="">
                                  <a href="Background-Machine-Learning.html" title="Background Machine Learning" class="">Background Machine Learning</a>
                                </li>
                                <li class="">
                                  <a href="Background-TensorFlow.html" title="Background TensorFlow" class="">Background TensorFlow</a>
                                </li>
                              </ul>  </li>
                          <li class="">
                            <span class="expand-stub"></span>
                            <a href="Installation.html" title="Installation &amp; Setup" class="">Installation &amp; Setup</a>
                              
                              <ul class="nav level3">
                                <li class="">
                                  <a href="Background-Jupyter.html" title="Background Jupyter Notebooks" class="">Background Jupyter Notebooks</a>
                                </li>
                                <li class="">
                                  <a href="Using-Docker.html" title="Background Docker Setup" class="">Background Docker Setup</a>
                                </li>
                              </ul>  </li>
                          <li class="">
                            <a href="Getting-Started-with-Balance-Ball.html" title="Getting Started with the 3D Balance Ball Environment" class="">Getting Started with the 3D Balance Ball Environment</a>
                          </li>
                          <li class="active">
                            <a href="Learning-Environment-Examples.html" title="Example Environment" class="active">Example Environment</a>
                          </li>
                        </ul>  </li>
                    <li class="">
                      <span class="expand-stub"></span>
                      <a class="">Creating Learning Environments</a>
                        
                        <ul class="nav level2">
                          <li class="">
                            <a href="Learning-Environment-Create-New.html" title="Making a New Learning environment" class="">Making a New Learning environment</a>
                          </li>
                          <li class="">
                            <a href="Learning-Environment-Design.html" title="Designing a Learning environment" class="">Designing a Learning environment</a>
                          </li>
                          <li class="">
                            <a href="Learning-Environment-Best-Practices.html" title="Learning Environment Best Practices" class="">Learning Environment Best Practices</a>
                          </li>
                          <li class="">
                            <a href="Feature-Monitor.html" title="Using the Monitor Class" class="">Using the Monitor Class</a>
                          </li>
                          <li class="">
                            <a href="Using-TensorFlow-Sharp-in-Unity.html" title="TensorFlowSharp in Unity" class="">TensorFlowSharp in Unity</a>
                          </li>
                        </ul>  </li>
                    <li class="">
                      <span class="expand-stub"></span>
                      <a class="">Training</a>
                        
                        <ul class="nav level2">
                          <li class="">
                            <a href="Training-ML-Agents.html" title="Training ML-Agents" class="">Training ML-Agents</a>
                          </li>
                          <li class="">
                            <a href="Training-PPO.html" title="Training with Proximal Policy Optimization" class="">Training with Proximal Policy Optimization</a>
                          </li>
                          <li class="">
                            <a href="Training-Curriculum-Learning.html" title="Training with Curriculum Learning" class="">Training with Curriculum Learning</a>
                          </li>
                          <li class="">
                            <a href="Training-Imitation-Learning.html" title="Training with Imitation Learning" class="">Training with Imitation Learning</a>
                          </li>
                          <li class="">
                            <a href="Feature-Memory.html" title="Training with LSTM" class="">Training with LSTM</a>
                          </li>
                          <li class="">
                            <a href="Training-on-Amazon-Web-Service.html" title="Training on the Cloud with Amazon Web Services" class="">Training on the Cloud with Amazon Web Services</a>
                          </li>
                          <li class="">
                            <a href="Using-Tensorboard.html" title="Using TensorBoard to Observe Training" class="">Using TensorBoard to Observe Training</a>
                          </li>
                        </ul>  </li>
                    <li class="">
                      <span class="expand-stub"></span>
                      <a class="">Help</a>
                        
                        <ul class="nav level2">
                          <li class="">
                            <a href="Migrating-v0.3.html" title="Migrating to ML-Agents v.0.3" class="">Migrating to ML-Agents v.0.3</a>
                          </li>
                          <li class="">
                            <a href="Glossary.html" title="ML-Agents Glossary" class="">ML-Agents Glossary</a>
                          </li>
                          <li class="">
                            <a href="Limitations-and-Common-Issues.html" title="Limitations &amp; Common Issues" class="">Limitations &amp; Common Issues</a>
                          </li>
                        </ul>  </li>
                  </ul>        </div>
              </div>
            </div>
          </div>
        </div>
        <div class="article row grid-right">
          <div class="col-md-10">
            <article class="content wrap" id="_content" data-uid="">
<h1 id="example-learning-environments">Example Learning Environments</h1>

<p>Unity ML-Agents contains an expanding set of example environments which
demonstrate various features of the platform. Environments are located in 
<code>unity-environment/Assets/ML-Agents/Examples</code> and summarized below. 
Additionally, our 
<a href="https://connect.unity.com/challenges/ml-agents-1">first ML Challenge</a>
contains environments created by the community.</p>
<p>This page only overviews the example environments we provide. To learn more
on how to design and build your own environments see our 
<a href="Learning-Environment-Create-New.html">Making a New Learning Environment</a>
page.</p>
<p>If you would like to contribute environments, please see our 
<a href="../CONTRIBUTING.md">contribution guidelines</a> page. </p>
<h2 id="basic">Basic</h2>
<p><img src="../images/basic.png" alt="Basic"></p>
<ul>
<li>Set-up: A linear movement task where the agent must move left or right to rewarding states.</li>
<li>Goal: Move to the most reward state.</li>
<li>Agents: The environment contains one agent linked to a single brain.</li>
<li>Agent Reward Function: <ul>
<li>+0.1 for arriving at suboptimal state.</li>
<li>+1.0 for arriving at optimal state.</li>
</ul>
</li>
<li>Brains: One brain with the following observation/action space.<ul>
<li>Vector Observation space: (Discrete) One variable corresponding to current state.</li>
<li>Vector Action space: (Discrete) Two possible actions (Move left, move right).</li>
<li>Visual Observations: 0</li>
</ul>
</li>
<li>Reset Parameters: None</li>
</ul>
<h2 id="3dball-3d-balance-ball">3DBall: 3D Balance Ball</h2>
<p><img src="../images/balance.png" alt="3D Balance Ball"></p>
<ul>
<li>Set-up: A balance-ball task, where the agent controls the platform. </li>
<li>Goal: The agent must balance the platform in order to keep the ball on it for as long as possible.</li>
<li>Agents: The environment contains 12 agents of the same kind, all linked to a single brain.</li>
<li>Agent Reward Function: <ul>
<li>+0.1 for every step the ball remains on the platform. </li>
<li>-1.0 if the ball falls from the platform.</li>
</ul>
</li>
<li>Brains: One brain with the following observation/action space.<ul>
<li>Vector Observation space: (Continuous) 8 variables corresponding to rotation of platform, and position, rotation, and velocity of ball.</li>
<li>Vector Observation space (Hard Version): (Continuous) 5 variables corresponding to rotation of platform and position and rotation of ball.</li>
<li>Vector Action space: (Continuous) Size of 2, with one value corresponding to X-rotation, and the other to Z-rotation.</li>
<li>Visual Observations: 0</li>
</ul>
</li>
<li>Reset Parameters: None</li>
</ul>
<h2 id="gridworld">GridWorld</h2>
<p><img src="../images/gridworld.png" alt="GridWorld"></p>
<ul>
<li>Set-up: A version of the classic grid-world task. Scene contains agent, goal, and obstacles. </li>
<li>Goal: The agent must navigate the grid to the goal while avoiding the obstacles.</li>
<li>Agents: The environment contains one agent linked to a single brain.</li>
<li>Agent Reward Function: <ul>
<li>-0.01 for every step.</li>
<li>+1.0 if the agent navigates to the goal position of the grid (episode ends).</li>
<li>-1.0 if the agent navigates to an obstacle (episode ends).</li>
</ul>
</li>
<li>Brains: One brain with the following observation/action space.<ul>
<li>Vector Observation space: None</li>
<li>Vector Action space: (Discrete) Size of 4, corresponding to movement in cardinal directions.</li>
<li>Visual Observations: One corresponding to top-down view of GridWorld.</li>
</ul>
</li>
<li>Reset Parameters: Three, corresponding to grid size, number of obstacles, and number of goals.</li>
</ul>
<h2 id="tennis">Tennis</h2>
<p><img src="../images/tennis.png" alt="Tennis"></p>
<ul>
<li>Set-up: Two-player game where agents control rackets to bounce ball over a net. </li>
<li>Goal: The agents must bounce ball between one another while not dropping or sending ball out of bounds.</li>
<li>Agents: The environment contains two agent linked to a single brain named TennisBrain. After training you can attach another brain named MyBrain to one of the agent to play against your trained model. </li>
<li>Agent Reward Function (independent): <ul>
<li>+0.1 To agent when hitting ball over net.</li>
<li>-0.1 To agent who let ball hit their ground, or hit ball out of bounds.</li>
</ul>
</li>
<li>Brains: One brain with the following observation/action space.<ul>
<li>Vector Observation space: (Continuous) 8 variables corresponding to position and velocity of ball and racket.</li>
<li>Vector Action space: (Continuous) Size of 2, corresponding to movement toward net or away from net, and jumping.</li>
<li>Visual Observations: None</li>
</ul>
</li>
<li>Reset Parameters: One, corresponding to size of ball.</li>
</ul>
<h2 id="push-block">Push Block</h2>
<p><img src="../images/push.png" alt="Push"></p>
<ul>
<li>Set-up: A platforming environment where the agent can push a block around.</li>
<li>Goal: The agent must push the block to the goal.</li>
<li>Agents: The environment contains one agent linked to a single brain.</li>
<li>Agent Reward Function: <ul>
<li>-0.0025 for every step.</li>
<li>+1.0 if the block touches the goal.</li>
</ul>
</li>
<li>Brains: One brain with the following observation/action space.<ul>
<li>Vector Observation space: (Continuous) 15 variables corresponding to position and velocities of agent, block, and goal.</li>
<li>Vector Action space: (Continuous) Size of 2, corresponding to movement in X and Z directions.</li>
<li>Visual Observations: None.</li>
</ul>
</li>
<li>Reset Parameters: None.</li>
</ul>
<h2 id="wall-jump">Wall Jump</h2>
<p><img src="../images/wall.png" alt="Wall"></p>
<ul>
<li>Set-up: A platforming environment where the agent can jump over a wall.</li>
<li>Goal: The agent must use the block to scale the wall and reach the goal.</li>
<li>Agents: The environment contains one agent linked to two different brains. The brain the agent is linked to changes depending on the height of the wall.</li>
<li>Agent Reward Function: <ul>
<li>-0.0005 for every step.</li>
<li>+1.0 if the agent touches the goal.</li>
<li>-1.0 if the agent falls off the platform.</li>
</ul>
</li>
<li>Brains: Two brains, each with the following observation/action space.<ul>
<li>Vector Observation space: (Continuous) 16 variables corresponding to position and velocities of agent, block, and goal, plus the height of the wall.</li>
<li>Vector Action space: (Discrete) Size of 74, corresponding to 14 raycasts each detecting 4 possible objects. plus the global position of the agent and whether or not the agent is grounded.</li>
<li>Visual Observations: None.</li>
</ul>
</li>
<li>Reset Parameters: 4, corresponding to the height of the possible walls.</li>
</ul>
<h2 id="reacher">Reacher</h2>
<p><img src="../images/reacher.png" alt="Tennis"></p>
<ul>
<li>Set-up: Double-jointed arm which can move to target locations.</li>
<li>Goal: The agents must move it&#39;s hand to the goal location, and keep it there.</li>
<li>Agents: The environment contains 32 agent linked to a single brain.</li>
<li>Agent Reward Function (independent): <ul>
<li>+0.1 Each step agent&#39;s hand is in goal location.</li>
</ul>
</li>
<li>Brains: One brain with the following observation/action space.<ul>
<li>Vector Observation space: (Continuous) 26 variables corresponding to position, rotation, velocity, and angular velocities of the two arm Rigidbodies.</li>
<li>Vector Action space: (Continuous) Size of 4, corresponding to torque applicable to two joints. </li>
<li>Visual Observations: None</li>
</ul>
</li>
<li>Reset Parameters: Two, corresponding to goal size, and goal movement speed.</li>
</ul>
<h2 id="crawler">Crawler</h2>
<p><img src="../images/crawler.png" alt="Crawler"></p>
<ul>
<li>Set-up: A creature with 4 arms and 4 forearms.</li>
<li>Goal: The agents must move its body along the x axis without falling.</li>
<li>Agents: The environment contains 3 agent linked to a single brain.</li>
<li>Agent Reward Function (independent): <ul>
<li>+1 times velocity in the x direction</li>
<li>-1 for falling.</li>
<li>-0.01 times the action squared</li>
<li>-0.05 times y position change</li>
<li>-0.05 times velocity in the z direction </li>
</ul>
</li>
<li>Brains: One brain with the following observation/action space.<ul>
<li>Vector Observation space: (Continuous) 117 variables corresponding to position, rotation, velocity, and angular velocities of each limb plus the acceleration and angular acceleration of the body.</li>
<li>Vector Action space: (Continuous) Size of 12, corresponding to torque applicable to 12 joints. </li>
<li>Visual Observations: None</li>
</ul>
</li>
<li>Reset Parameters: None</li>
</ul>
<h2 id="banana-collector">Banana Collector</h2>
<p><img src="../images/banana.png" alt="Banana"></p>
<ul>
<li>Set-up: A multi-agent environment where agents compete to collect bananas. </li>
<li>Goal: The agents must learn to move to as many yellow bananas as possible while avoiding red bananas.</li>
<li>Agents: The environment contains 10 agents linked to a single brain.</li>
<li>Agent Reward Function (independent): <ul>
<li>+1 for interaction with yellow banana</li>
<li>-1 for interaction with red banana.</li>
</ul>
</li>
<li>Brains: One brain with the following observation/action space.<ul>
<li>Vector Observation space: (Continuous) 51 corresponding to velocity of agent, plus ray-based perception of objects around agent&#39;s forward direction.</li>
<li>Vector Action space: (Continuous) Size of 3, corresponding to forward movement, y-axis rotation, and whether to use laser to disable other agents.</li>
<li>Visual Observations (Optional): First-person view for each agent. </li>
</ul>
</li>
<li>Reset Parameters: None</li>
</ul>
<h2 id="hallway">Hallway</h2>
<p><img src="../images/hallway.png" alt="Hallway"></p>
<ul>
<li>Set-up: Environment where the agent needs to find information in a room, remember it, and use it to move to the correct goal.</li>
<li>Goal: Move to the goal which corresponds to the color of the block in the room.</li>
<li>Agents: The environment contains one agent linked to a single brain.</li>
<li>Agent Reward Function (independent):<ul>
<li>+1 For moving to correct goal.</li>
<li>-0.1 For moving to incorrect goal.</li>
<li>-0.0003 Existential penalty.</li>
</ul>
</li>
<li>Brains: One brain with the following observation/action space:<ul>
<li>Vector Observation space: (Continuous) 30 corresponding to local ray-casts detecting objects, goals, and walls.</li>
<li>Vector Action space: (Discrete) 4 corresponding to agent rotation and forward/backward movement.</li>
<li>Visual Observations (Optional): First-person view for the agent.</li>
</ul>
</li>
<li>Reset Parameters: None</li>
</ul>
<h2 id="bouncer">Bouncer</h2>
<p><img src="../images/bouncer.png" alt="Bouncer"></p>
<ul>
<li>Set-up: Environment where the agent needs on-demand decision making. The agent must decide how perform its next bounce only when it touches the ground.</li>
<li>Goal: Catch the floating banana. Only has a limited number of jumps.</li>
<li>Agents: The environment contains one agent linked to a single brain.</li>
<li>Agent Reward Function (independent):<ul>
<li>+1 For catching the banana.</li>
<li>-1 For bouncing out of bounds.</li>
<li>-0.05 Times the action squared. Energy expenditure penalty.</li>
</ul>
</li>
<li>Brains: One brain with the following observation/action space:<ul>
<li>Vector Observation space: (Continuous) 6 corresponding to local position of agent and banana.</li>
<li>Vector Action space: (Continuous) 3 corresponding to agent force applied for the jump.</li>
<li>Visual Observations: None</li>
</ul>
</li>
<li>Reset Parameters: None</li>
</ul>
<h2 id="soccer-twos">Soccer Twos</h2>
<p><img src="../images/soccer.png" alt="SoccerTwos"></p>
<ul>
<li>Set-up: Environment where four agents compete in a 2 vs 2 toy soccer game. </li>
<li>Goal:<ul>
<li>Striker: Get the ball into the opponent&#39;s goal.</li>
<li>Goalie: Prevent the ball from entering its own goal.</li>
</ul>
</li>
<li>Agents: The environment contains four agents, with two linked to one brain (strikers) and two linked to another (goalies).</li>
<li>Agent Reward Function (dependent):<ul>
<li>Striker:<ul>
<li>+1 When ball enters opponent&#39;s goal.</li>
<li>-0.1 When ball enters own team&#39;s goal.</li>
<li>-0.001 Existential penalty.</li>
</ul>
</li>
<li>Goalie:<ul>
<li>-1 When ball enters team&#39;s goal.</li>
<li>+0.1 When ball enters opponents goal.</li>
<li>+0.001 Existential bonus.</li>
</ul>
</li>
</ul>
</li>
<li>Brains: Two brain with the following observation/action space:<ul>
<li>Vector Observation space: (Continuous) 112 corresponding to local 14 ray casts, each detecting 7 possible object types, along with the object&#39;s distance. Perception is in 180 degree view from front of agent.</li>
<li>Vector Action space: (Discrete) <ul>
<li>Striker: 6 corresponding to forward, backward, sideways movement, as well as rotation.</li>
<li>Goalie: 4 corresponding to forward, backward, sideways movement.</li>
</ul>
</li>
<li>Visual Observations: None</li>
</ul>
</li>
<li>Reset Parameters: None</li>
</ul>
</article>
          </div>
          
          <div class="hidden-sm col-md-2" role="complementary">
            <div class="sideaffix">
              <div class="contribution">
                <ul class="nav">
                  <li>
                    <a href="https://github.com/Unity-Technologies/ml-agents/blob/feature-docfx/doc-src/articles/Learning-Environment-Examples.md/#L1" class="contribution-link">Improve this Doc</a>
                  </li>
                </ul>
              </div>
              <nav class="bs-docs-sidebar hidden-print hidden-xs hidden-sm affix" id="affix">
              <!-- <p><a class="back-to-top" href="#top">Back to top</a><p> -->
              </nav>
            </div>
          </div>
        </div>
      </div>
      
      <footer>
        <div class="grad-bottom"></div>
        <div class="footer">
          <div class="container">
            <span class="pull-right">
              <a href="#top">Back to top</a>
            </span>
            
            <span>Generated by <strong>DocFX</strong></span>
          </div>
        </div>
      </footer>
    </div>
    
    <script type="text/javascript" src="../styles/docfx.vendor.js"></script>
    <script type="text/javascript" src="../styles/docfx.js"></script>
    <script type="text/javascript" src="../styles/main.js"></script>
  </body>
</html>
